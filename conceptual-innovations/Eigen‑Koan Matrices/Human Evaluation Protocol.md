HUMAN EVALUATION PROTOCOL: EKM OUTPUTS
--------------------------------------

OBJECTIVE:
Validate machine metrics with human judgment on EKM traversal outputs.

PARTICIPANTS:
- 12-15 evaluators with diverse backgrounds
- Mix of technical and humanities expertise

MATERIALS:
1. Set of 10 EKM traversal outputs per model (50 total)
2. Outputs presented without model identification (blind evaluation)
3. Original EKM grids and traversal paths provided for context

PROCEDURE:
1. Training phase:
   - Educate evaluators on EKM concepts and evaluation criteria
   - Practice evaluations with feedback on sample outputs

2. Evaluation phase:
   - Rate each output on 7-point Likert scales for:
     * Narrative coherence
     * Affective resonance
     * Constraint satisfaction
     * Creative novelty
   - Provide qualitative commentary on traversal choices

3. Comparative phase:
   - Force-rank outputs on overall quality
   - Identify most distinctive stylistic features
   - Match outputs to likely source models (if possible)

ANALYSIS:
- Inter-rater reliability calculation
- Correlation between human and automatic metrics
- Qualitative thematic analysis of commentaries
- Model identification accuracy analysis
